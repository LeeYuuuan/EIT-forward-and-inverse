{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PRA-qnqtfXUIyc8zFtMLqhPXdY52oPM9",
      "authorship_tag": "ABX9TyNiAb5FwePVUAAqgHHzRFY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeYuuuan/EIT-forward-and-inverse/blob/main/Biyesheji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m3cOrqn6b27o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader,Dataset\n",
        "from torch.autograd import Variable # 获取变量\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(r\"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning\")\n",
        "import torch_rbf as rbf"
      ],
      "metadata": {
        "id": "8jvGlzJUeTgo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DealDataset(Dataset):\n",
        "\n",
        "    def __init__(self, a):\n",
        "        \n",
        "        # load the .csv simulation data\n",
        "        dic_path = \"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/data/\"\n",
        "        X = np.loadtxt(dic_path + 'datacsv1.csv', delimiter=';', dtype=np.float32)\n",
        "        y = np.loadtxt(dic_path + 'datacsv.csv', delimiter=';', dtype=np.float32)\n",
        "\n",
        "        # split train/test dataset\n",
        "        X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "        X_train = np.zeros([X_train1.shape[0], 1, 16, 12]) # shape: count * 1 * 16(angle) * 12(voltage)\n",
        "        X_test = np.zeros([X_test1.shape[0], 1, 16, 12])\n",
        "\n",
        "        # return different data\n",
        "        if a == 'train':\n",
        "            self.x = X_train\n",
        "            self.y = y_train\n",
        "            self.len = X_train.shape[0]\n",
        "        elif a == 'test':\n",
        "            self.x = X_test\n",
        "            self.y = y_test\n",
        "            self.len = X_test.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "EdZJsZdjfWFC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义网络结构\n",
        "class CNNnet(torch.nn.Module):\n",
        "    def __init__(self, layer_widths, layer_centres, basis_func):\n",
        "        super(CNNnet,self).__init__()\n",
        "        self.rbf_layers = nn.ModuleList()\n",
        "        self.linear_layers = nn.ModuleList()\n",
        "        self.conv1_1 = nn.Sequential(\n",
        "            # (1, 16, 12)pytorch输入不用定义大小，因为参数过多写成nn.Conv2d(1,64,3,1，1)形式容易出错，有的参数默认了\n",
        "            nn.Conv2d(\n",
        "                in_channels=1, # 单通道\n",
        "                out_channels=64, # 64通道\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1 # 零填充\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64), # 批量归一化\n",
        "            nn.ELU(), # ELU激活函数\n",
        "        )\n",
        "        self.conv1_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=64,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 最大池化层，核大小为2\n",
        "        )\n",
        "        self.conv2_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv2_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2,ceil_mode=True) # 平均池化层，核大小为2，2×1经过这层变成1×0，报错，但有ceil_mode=True为向上取整，变成1×1\n",
        "        )\n",
        "        for i in range(len(layer_widths) - 1):\n",
        "            self.rbf_layers.append(rbf.RBF(layer_widths[i], layer_centres[i], basis_func))\n",
        "            self.linear_layers.append(nn.Linear(layer_centres[i], layer_widths[i + 1]))\n",
        "        self.mlp2 = torch.nn.Linear(512,576) # 输出层，512是输入这层的大小，576是输出的大小\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"forward  propagation\"\"\"\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.conv3_4(x)\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.conv4_4(x)\n",
        "        x = x.view(x.size(0),-1) # 四维数据（数据量，通道，纵向，横向），展开为二维（数据量，只有横向）\n",
        "        for i in range(len(self.rbf_layers)):\n",
        "            x = self.rbf_layers[i](x)\n",
        "            x = self.linear_layers[i](x)\n",
        "        x = self.mlp2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yATezHZWmQcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Dataset\n",
        "dealDataset1 = DealDataset(a = 'train')\n",
        "\n",
        "#将这个类传给DataLoader\n",
        "train_loader = DataLoader(dataset=dealDataset1,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True)"
      ],
      "metadata": {
        "id": "BL014BErl65q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_widths = [512] #神经元数量\n",
        "layer_centres = [40]\n",
        "basis_func = rbf.gaussian #初始偏置\n",
        "\n",
        "model = CNNnet(layer_widths, layer_centres, basis_func) #初始化模型\n",
        "print(model)  #显示模型参数\n",
        "model = model.float() #模型参数转为float型\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device) #训练数据和模型数据类型要统一，并且pytorch-gpu数据类型要变成指定类型\n",
        "\n",
        "loss_func = torch.nn.MSELoss() #定义损失函数\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.3, momentum=0.9) #动量梯度下降法\n",
        "\n",
        "dealDataset2 = DealDataset(a='test')  #测试集数据\n",
        "\n",
        "test_loader = DataLoader(dataset=dealDataset2,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True)\n"
      ],
      "metadata": {
        "id": "rtjJPbU4ngK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "下面矩阵存放训练过程中损失函数等数据\n",
        "'''\n",
        "loss_count = []\n",
        "iter_loss = []\n",
        "batch_loss = []\n",
        "test_loss = []\n",
        "epochs=100 "
      ],
      "metadata": {
        "id": "zMq-xL1LnswX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, (x, y)in enumerate(train_loader):\n",
        "        batch_x = Variable(x).to(torch.float32) # torch.Size([, 1, 16, 12])\n",
        "        batch_x = batch_x.cuda()\n",
        "        batch_y = Variable(y).to(torch.float32) # torch.Size([576])\n",
        "        batch_y = batch_y.cuda()\n",
        "        out = model(batch_x)        # 获取最后输出\n",
        "        loss = loss_func(out, batch_y)        # 获取损失\n",
        "        batch_loss.append(loss.cuda().data.cpu().numpy())    # 使用优化器优化损失\n",
        "        opt.zero_grad()  # 清空上一步残余更新参数值\n",
        "        loss.backward() # 误差反向传播，计算参数更新值\n",
        "        opt.step() # 将参数更新值施加到net的parmeters上\n",
        "        '''\n",
        "        每20个数据显示一次训练集均方误差\n",
        "        '''\n",
        "        if i%20 == 0:\n",
        "            loss_count.append(loss)\n",
        "            print('train MSE {}:\\t'.format(i), loss.item())\n",
        "            torch.save(model,r'C:\\Users\\luoxinyu\\Desktop\\log_CNN')\n",
        "\n",
        "    for a,b in test_loader:\n",
        "        test_x = Variable(a).to(torch.float32)\n",
        "        test_x = test_x.cuda()\n",
        "        test_y = Variable(b).to(torch.float32)\n",
        "        test_y = test_y.cuda()\n",
        "        out = model(test_x)\n",
        "        loss = loss_func(out, test_y)\n",
        "        test_loss.append(loss.cuda().data.cpu().numpy())\n",
        "        '''\n",
        "        每轮示一次训练集均方误差\n",
        "        '''\n",
        "        print('test MSE {}:\\t'.format(epoch+1), loss.item())\n",
        "        break\n",
        "    iter_loss.append(np.average(np.array(batch_loss)))\n",
        "\n",
        "'''\n",
        "绘制测试集 轮数与均方误差图像\n",
        "'''\n",
        "x = np.arange(epochs)\n",
        "y = np.array(iter_loss)\n",
        "plt.plot(x, y)\n",
        "plt.title('pic')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D3C_5M-BmH0o",
        "outputId": "d1e7ebd7-c1c4-4f2a-e17d-63bb24695a66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train MSE 0:\t 0.03841310739517212\n",
            "train MSE 20:\t 0.004044792614877224\n",
            "train MSE 40:\t 0.0019904563669115305\n",
            "test MSE 1:\t 0.0020046543795615435\n",
            "train MSE 0:\t 0.0019654103089123964\n",
            "train MSE 20:\t 0.0019267505267634988\n",
            "train MSE 40:\t 0.0019031645497307181\n",
            "test MSE 2:\t 0.0019473271677270532\n",
            "train MSE 0:\t 0.0019074674928560853\n",
            "train MSE 20:\t 0.0018639753106981516\n",
            "train MSE 40:\t 0.0019892831332981586\n",
            "test MSE 3:\t 0.001889503444544971\n",
            "train MSE 0:\t 0.0019533217418938875\n",
            "train MSE 20:\t 0.0018974026897922158\n",
            "train MSE 40:\t 0.0019755433313548565\n",
            "test MSE 4:\t 0.002024107612669468\n",
            "train MSE 0:\t 0.0019201521063223481\n",
            "train MSE 20:\t 0.0018886636244133115\n",
            "train MSE 40:\t 0.0019347568741068244\n",
            "test MSE 5:\t 0.002000292530283332\n",
            "train MSE 0:\t 0.001914651831611991\n",
            "train MSE 20:\t 0.0019428572850301862\n",
            "train MSE 40:\t 0.0018941470189020038\n",
            "test MSE 6:\t 0.0019312658114358783\n",
            "train MSE 0:\t 0.0019455676665529609\n",
            "train MSE 20:\t 0.0018894049571827054\n",
            "train MSE 40:\t 0.001959926215931773\n",
            "test MSE 7:\t 0.001988004893064499\n",
            "train MSE 0:\t 0.0019987530540674925\n",
            "train MSE 20:\t 0.001961721107363701\n",
            "train MSE 40:\t 0.001945644267834723\n",
            "test MSE 8:\t 0.001881853211671114\n",
            "train MSE 0:\t 0.001930245547555387\n",
            "train MSE 20:\t 0.0020125608425587416\n",
            "train MSE 40:\t 0.0019654419738799334\n",
            "test MSE 9:\t 0.0019169048173353076\n",
            "train MSE 0:\t 0.0019460783805698156\n",
            "train MSE 20:\t 0.0019291440257802606\n",
            "train MSE 40:\t 0.0019170109881088138\n",
            "test MSE 10:\t 0.0019776090048253536\n",
            "train MSE 0:\t 0.0019464731449261308\n",
            "train MSE 20:\t 0.0020246761851012707\n",
            "train MSE 40:\t 0.0019758695270866156\n",
            "test MSE 11:\t 0.0019400236196815968\n",
            "train MSE 0:\t 0.0019427641527727246\n",
            "train MSE 20:\t 0.0019628601148724556\n",
            "train MSE 40:\t 0.0019072869326919317\n",
            "test MSE 12:\t 0.0019813880790024996\n",
            "train MSE 0:\t 0.0019055373268201947\n",
            "train MSE 20:\t 0.001923759002238512\n",
            "train MSE 40:\t 0.002026316709816456\n",
            "test MSE 13:\t 0.001954999752342701\n",
            "train MSE 0:\t 0.0019893692806363106\n",
            "train MSE 20:\t 0.0019528681878000498\n",
            "train MSE 40:\t 0.0018819732358679175\n",
            "test MSE 14:\t 0.001895975903607905\n",
            "train MSE 0:\t 0.0019400101155042648\n",
            "train MSE 20:\t 0.0020114306826144457\n",
            "train MSE 40:\t 0.0019062128849327564\n",
            "test MSE 15:\t 0.00202033924870193\n",
            "train MSE 0:\t 0.0019374308176338673\n",
            "train MSE 20:\t 0.0019093155860900879\n",
            "train MSE 40:\t 0.0019251182675361633\n",
            "test MSE 16:\t 0.0019357709679752588\n",
            "train MSE 0:\t 0.0019439330790191889\n",
            "train MSE 20:\t 0.00200203456915915\n",
            "train MSE 40:\t 0.0018376861698925495\n",
            "test MSE 17:\t 0.0019912966527044773\n",
            "train MSE 0:\t 0.0019124873215332627\n",
            "train MSE 20:\t 0.0019426760263741016\n",
            "train MSE 40:\t 0.0018899163696914911\n",
            "test MSE 18:\t 0.0019379742443561554\n",
            "train MSE 0:\t 0.0019370830850675702\n",
            "train MSE 20:\t 0.0019748827908188105\n",
            "train MSE 40:\t 0.0019665854051709175\n",
            "test MSE 19:\t 0.001950741047039628\n",
            "train MSE 0:\t 0.0019189883023500443\n",
            "train MSE 20:\t 0.001894191955216229\n",
            "train MSE 40:\t 0.0020032392349094152\n",
            "test MSE 20:\t 0.0019492184510454535\n",
            "train MSE 0:\t 0.0019083325751125813\n",
            "train MSE 20:\t 0.0019266919698566198\n",
            "train MSE 40:\t 0.001880406984128058\n",
            "test MSE 21:\t 0.001992515753954649\n",
            "train MSE 0:\t 0.0019196876091882586\n",
            "train MSE 20:\t 0.0019092761212959886\n",
            "train MSE 40:\t 0.0019550796132534742\n",
            "test MSE 22:\t 0.0020603809971362352\n",
            "train MSE 0:\t 0.001887237885966897\n",
            "train MSE 20:\t 0.0019552165176719427\n",
            "train MSE 40:\t 0.0019434831338003278\n",
            "test MSE 23:\t 0.001983922440558672\n",
            "train MSE 0:\t 0.0019670873880386353\n",
            "train MSE 20:\t 0.0019936731550842524\n",
            "train MSE 40:\t 0.0018893943633884192\n",
            "test MSE 24:\t 0.001898998860269785\n",
            "train MSE 0:\t 0.0019527421100065112\n",
            "train MSE 20:\t 0.0019258952233940363\n",
            "train MSE 40:\t 0.001955147134140134\n",
            "test MSE 25:\t 0.0019052393035963178\n",
            "train MSE 0:\t 0.001982045592740178\n",
            "train MSE 20:\t 0.0019911022391170263\n",
            "train MSE 40:\t 0.0018941810121759772\n",
            "test MSE 26:\t 0.0018995706923305988\n",
            "train MSE 0:\t 0.0020102954003959894\n",
            "train MSE 20:\t 0.0019718364346772432\n",
            "train MSE 40:\t 0.0018872121581807733\n",
            "test MSE 27:\t 0.0019212220795452595\n",
            "train MSE 0:\t 0.0019883543718606234\n",
            "train MSE 20:\t 0.001969292527064681\n",
            "train MSE 40:\t 0.0018747895956039429\n",
            "test MSE 28:\t 0.0019424996571615338\n",
            "train MSE 0:\t 0.0019329884089529514\n",
            "train MSE 20:\t 0.0018510182853788137\n",
            "train MSE 40:\t 0.0019823878537863493\n",
            "test MSE 29:\t 0.001998867839574814\n",
            "train MSE 0:\t 0.0020335044246166945\n",
            "train MSE 20:\t 0.001863198122009635\n",
            "train MSE 40:\t 0.002007025061175227\n",
            "test MSE 30:\t 0.0019346406916156411\n",
            "train MSE 0:\t 0.0019159178482368588\n",
            "train MSE 20:\t 0.0019421234028413892\n",
            "train MSE 40:\t 0.0018777735531330109\n",
            "test MSE 31:\t 0.001977509120479226\n",
            "train MSE 0:\t 0.0019188241567462683\n",
            "train MSE 20:\t 0.001994140911847353\n",
            "train MSE 40:\t 0.0018537510186433792\n",
            "test MSE 32:\t 0.0018710701260715723\n",
            "train MSE 0:\t 0.0019094465533271432\n",
            "train MSE 20:\t 0.0020168565679341555\n",
            "train MSE 40:\t 0.0018985563656315207\n",
            "test MSE 33:\t 0.0019802015740424395\n",
            "train MSE 0:\t 0.0019049255643039942\n",
            "train MSE 20:\t 0.0020216896664351225\n",
            "train MSE 40:\t 0.0019161759410053492\n",
            "test MSE 34:\t 0.0019386425847187638\n",
            "train MSE 0:\t 0.0019936035387218\n",
            "train MSE 20:\t 0.0019221180118620396\n",
            "train MSE 40:\t 0.0018857195973396301\n",
            "test MSE 35:\t 0.0019034333527088165\n",
            "train MSE 0:\t 0.001911962404847145\n",
            "train MSE 20:\t 0.0019533054437488317\n",
            "train MSE 40:\t 0.0019301888532936573\n",
            "test MSE 36:\t 0.0019781251903623343\n",
            "train MSE 0:\t 0.0020405936520546675\n",
            "train MSE 20:\t 0.0019154093461111188\n",
            "train MSE 40:\t 0.001865739468485117\n",
            "test MSE 37:\t 0.0019922475330531597\n",
            "train MSE 0:\t 0.0019265187438577414\n",
            "train MSE 20:\t 0.0019950473215430975\n",
            "train MSE 40:\t 0.001987604657188058\n",
            "test MSE 38:\t 0.0019966759718954563\n",
            "train MSE 0:\t 0.0019311904907226562\n",
            "train MSE 20:\t 0.00194697140250355\n",
            "train MSE 40:\t 0.0020273211412131786\n",
            "test MSE 39:\t 0.001974414335563779\n",
            "train MSE 0:\t 0.001972679980099201\n",
            "train MSE 20:\t 0.0019709512125700712\n",
            "train MSE 40:\t 0.001952717313542962\n",
            "test MSE 40:\t 0.001992938108742237\n",
            "train MSE 0:\t 0.001965777250006795\n",
            "train MSE 20:\t 0.0019035699078813195\n",
            "train MSE 40:\t 0.0020572026260197163\n",
            "test MSE 41:\t 0.0019594829063862562\n",
            "train MSE 0:\t 0.0019515190506353974\n",
            "train MSE 20:\t 0.001973232487216592\n",
            "train MSE 40:\t 0.0019567746203392744\n",
            "test MSE 42:\t 0.001960381865501404\n",
            "train MSE 0:\t 0.0019475258886814117\n",
            "train MSE 20:\t 0.0019642512779682875\n",
            "train MSE 40:\t 0.001922589261084795\n",
            "test MSE 43:\t 0.001941223512403667\n",
            "train MSE 0:\t 0.0019521798240020871\n",
            "train MSE 20:\t 0.0018660716013982892\n",
            "train MSE 40:\t 0.0018546325154602528\n",
            "test MSE 44:\t 0.0019083783263340592\n",
            "train MSE 0:\t 0.0019448266830295324\n",
            "train MSE 20:\t 0.001974486978724599\n",
            "train MSE 40:\t 0.0019466595258563757\n",
            "test MSE 45:\t 0.0019396239658817649\n",
            "train MSE 0:\t 0.0019847697112709284\n",
            "train MSE 20:\t 0.0019696480594575405\n",
            "train MSE 40:\t 0.001853015273809433\n",
            "test MSE 46:\t 0.0019501799251884222\n",
            "train MSE 0:\t 0.0019044630462303758\n",
            "train MSE 20:\t 0.0020038255024701357\n",
            "train MSE 40:\t 0.00187897018622607\n",
            "test MSE 47:\t 0.0020425613038241863\n",
            "train MSE 0:\t 0.0019135408801957965\n",
            "train MSE 20:\t 0.0019527841359376907\n",
            "train MSE 40:\t 0.0019160894444212317\n",
            "test MSE 48:\t 0.0019772599916905165\n",
            "train MSE 0:\t 0.001968813594430685\n",
            "train MSE 20:\t 0.0019461398478597403\n",
            "train MSE 40:\t 0.0018944796174764633\n",
            "test MSE 49:\t 0.0019601427484303713\n",
            "train MSE 0:\t 0.0019200049573555589\n",
            "train MSE 20:\t 0.0019607343710958958\n",
            "train MSE 40:\t 0.0019494345178827643\n",
            "test MSE 50:\t 0.001965536968782544\n",
            "train MSE 0:\t 0.001931239734403789\n",
            "train MSE 20:\t 0.0019435555441305041\n",
            "train MSE 40:\t 0.002024315530434251\n",
            "test MSE 51:\t 0.002028264570981264\n",
            "train MSE 0:\t 0.0019233711063861847\n",
            "train MSE 20:\t 0.0019080849597230554\n",
            "train MSE 40:\t 0.001947173848748207\n",
            "test MSE 52:\t 0.001978551037609577\n",
            "train MSE 0:\t 0.0019082878716289997\n",
            "train MSE 20:\t 0.002020974876359105\n",
            "train MSE 40:\t 0.0020368800032883883\n",
            "test MSE 53:\t 0.001980380853638053\n",
            "train MSE 0:\t 0.00200720620341599\n",
            "train MSE 20:\t 0.001922817318700254\n",
            "train MSE 40:\t 0.0019343032035976648\n",
            "test MSE 54:\t 0.0018710996955633163\n",
            "train MSE 0:\t 0.0019540940411388874\n",
            "train MSE 20:\t 0.001929055550135672\n",
            "train MSE 40:\t 0.0019275008235126734\n",
            "test MSE 55:\t 0.0020448598079383373\n",
            "train MSE 0:\t 0.002027628244832158\n",
            "train MSE 20:\t 0.0019006052752956748\n",
            "train MSE 40:\t 0.001946735312230885\n",
            "test MSE 56:\t 0.0019887019880115986\n",
            "train MSE 0:\t 0.001876802067272365\n",
            "train MSE 20:\t 0.0019485453376546502\n",
            "train MSE 40:\t 0.0020008101128041744\n",
            "test MSE 57:\t 0.0019139705691486597\n",
            "train MSE 0:\t 0.0018929056823253632\n",
            "train MSE 20:\t 0.0019732576329261065\n",
            "train MSE 40:\t 0.001981101231649518\n",
            "test MSE 58:\t 0.0020164954476058483\n",
            "train MSE 0:\t 0.0019589781295508146\n",
            "train MSE 20:\t 0.0019646878354251385\n",
            "train MSE 40:\t 0.0018172559794038534\n",
            "test MSE 59:\t 0.0019983912352472544\n",
            "train MSE 0:\t 0.0018223358783870935\n",
            "train MSE 20:\t 0.0019187306752428412\n",
            "train MSE 40:\t 0.0020223818719387054\n",
            "test MSE 60:\t 0.001956837484613061\n",
            "train MSE 0:\t 0.0019898447208106518\n",
            "train MSE 20:\t 0.0019713016226887703\n",
            "train MSE 40:\t 0.0020000715740025043\n",
            "test MSE 61:\t 0.002006278373301029\n",
            "train MSE 0:\t 0.001953371334820986\n",
            "train MSE 20:\t 0.0020120632834732533\n",
            "train MSE 40:\t 0.0019447880331426859\n",
            "test MSE 62:\t 0.0019506700336933136\n",
            "train MSE 0:\t 0.0018580725882202387\n",
            "train MSE 20:\t 0.0018674839520826936\n",
            "train MSE 40:\t 0.0018947244388982654\n",
            "test MSE 63:\t 0.0019639090169221163\n",
            "train MSE 0:\t 0.001953492173925042\n",
            "train MSE 20:\t 0.0020095009822398424\n",
            "train MSE 40:\t 0.0019614004995673895\n",
            "test MSE 64:\t 0.0019481743220239878\n",
            "train MSE 0:\t 0.0018751766765490174\n",
            "train MSE 20:\t 0.0019209693418815732\n",
            "train MSE 40:\t 0.0019983360543847084\n",
            "test MSE 65:\t 0.0019747286569327116\n",
            "train MSE 0:\t 0.0018992801196873188\n",
            "train MSE 20:\t 0.0019401194294914603\n",
            "train MSE 40:\t 0.001960437512025237\n",
            "test MSE 66:\t 0.001923763076774776\n",
            "train MSE 0:\t 0.0019494068110361695\n",
            "train MSE 20:\t 0.0020478074438869953\n",
            "train MSE 40:\t 0.002004985697567463\n",
            "test MSE 67:\t 0.0020472740288823843\n",
            "train MSE 0:\t 0.0019298786064609885\n",
            "train MSE 20:\t 0.0018636611057445407\n",
            "train MSE 40:\t 0.001961908768862486\n",
            "test MSE 68:\t 0.0019118210766464472\n",
            "train MSE 0:\t 0.0019058776088058949\n",
            "train MSE 20:\t 0.001940969843417406\n",
            "train MSE 40:\t 0.0019686557352542877\n",
            "test MSE 69:\t 0.0019564239773899317\n",
            "train MSE 0:\t 0.002000390784814954\n",
            "train MSE 20:\t 0.0019471641862764955\n",
            "train MSE 40:\t 0.0020002189557999372\n",
            "test MSE 70:\t 0.0019583911634981632\n",
            "train MSE 0:\t 0.0019721880089491606\n",
            "train MSE 20:\t 0.002017929684370756\n",
            "train MSE 40:\t 0.001933243707753718\n",
            "test MSE 71:\t 0.002016573678702116\n",
            "train MSE 0:\t 0.0019206550205126405\n",
            "train MSE 20:\t 0.0019978578202426434\n",
            "train MSE 40:\t 0.0019197969231754541\n",
            "test MSE 72:\t 0.0019663472194224596\n",
            "train MSE 0:\t 0.0018696574261412024\n",
            "train MSE 20:\t 0.0020137056708335876\n",
            "train MSE 40:\t 0.0019798907451331615\n",
            "test MSE 73:\t 0.001951620215550065\n",
            "train MSE 0:\t 0.0019214828498661518\n",
            "train MSE 20:\t 0.0019080804195255041\n",
            "train MSE 40:\t 0.0019554169848561287\n",
            "test MSE 74:\t 0.001975748222321272\n",
            "train MSE 0:\t 0.0019636296201497316\n",
            "train MSE 20:\t 0.0020050876773893833\n",
            "train MSE 40:\t 0.0019065868109464645\n",
            "test MSE 75:\t 0.0018575526773929596\n",
            "train MSE 0:\t 0.0019882675260305405\n",
            "train MSE 20:\t 0.0019297274993732572\n",
            "train MSE 40:\t 0.001972517464309931\n",
            "test MSE 76:\t 0.0019458052702248096\n",
            "train MSE 0:\t 0.0019638927187770605\n",
            "train MSE 20:\t 0.001915332511998713\n",
            "train MSE 40:\t 0.001957258442416787\n",
            "test MSE 77:\t 0.001967190532013774\n",
            "train MSE 0:\t 0.0019217771477997303\n",
            "train MSE 20:\t 0.002011318225413561\n",
            "train MSE 40:\t 0.0018646506359800696\n",
            "test MSE 78:\t 0.0019095614552497864\n",
            "train MSE 0:\t 0.0018979829037562013\n",
            "train MSE 20:\t 0.001957828411832452\n",
            "train MSE 40:\t 0.0019270769553259015\n",
            "test MSE 79:\t 0.001936385058797896\n",
            "train MSE 0:\t 0.0019415068672969937\n",
            "train MSE 20:\t 0.001957398373633623\n",
            "train MSE 40:\t 0.0018971876706928015\n",
            "test MSE 80:\t 0.001957087544724345\n",
            "train MSE 0:\t 0.002066095359623432\n",
            "train MSE 20:\t 0.002043092390522361\n",
            "train MSE 40:\t 0.001974480925127864\n",
            "test MSE 81:\t 0.001967784482985735\n",
            "train MSE 0:\t 0.0020088793244212866\n",
            "train MSE 20:\t 0.0019309078343212605\n",
            "train MSE 40:\t 0.001955455867573619\n",
            "test MSE 82:\t 0.0019439487950876355\n",
            "train MSE 0:\t 0.002013026736676693\n",
            "train MSE 20:\t 0.0019419562304392457\n",
            "train MSE 40:\t 0.001900693867355585\n",
            "test MSE 83:\t 0.0019756508991122246\n",
            "train MSE 0:\t 0.0019326864276081324\n",
            "train MSE 20:\t 0.0019334445241838694\n",
            "train MSE 40:\t 0.001889140927232802\n",
            "test MSE 84:\t 0.0019468896789476275\n",
            "train MSE 0:\t 0.0018970167730003595\n",
            "train MSE 20:\t 0.0018735697958618402\n",
            "train MSE 40:\t 0.0019522514194250107\n",
            "test MSE 85:\t 0.0020024359691888094\n",
            "train MSE 0:\t 0.002018469851464033\n",
            "train MSE 20:\t 0.001975278602913022\n",
            "train MSE 40:\t 0.0019421590259298682\n",
            "test MSE 86:\t 0.0019852204713970423\n",
            "train MSE 0:\t 0.0019785575568675995\n",
            "train MSE 20:\t 0.002022052649408579\n",
            "train MSE 40:\t 0.0019464861834421754\n",
            "test MSE 87:\t 0.001982075162231922\n",
            "train MSE 0:\t 0.0019990582950413227\n",
            "train MSE 20:\t 0.001969385426491499\n",
            "train MSE 40:\t 0.0019127933774143457\n",
            "test MSE 88:\t 0.0019747477490454912\n",
            "train MSE 0:\t 0.001945259515196085\n",
            "train MSE 20:\t 0.0019270413322374225\n",
            "train MSE 40:\t 0.0019603963010013103\n",
            "test MSE 89:\t 0.001988454023376107\n",
            "train MSE 0:\t 0.0019846162758767605\n",
            "train MSE 20:\t 0.001994343940168619\n",
            "train MSE 40:\t 0.0019144798861816525\n",
            "test MSE 90:\t 0.00203357613645494\n",
            "train MSE 0:\t 0.0019755300600081682\n",
            "train MSE 20:\t 0.001929175341501832\n",
            "train MSE 40:\t 0.0019034325378015637\n",
            "test MSE 91:\t 0.0018977911677211523\n",
            "train MSE 0:\t 0.0019867524970322847\n",
            "train MSE 20:\t 0.0019078064942732453\n",
            "train MSE 40:\t 0.001928849727846682\n",
            "test MSE 92:\t 0.0019520597998052835\n",
            "train MSE 0:\t 0.001952458987943828\n",
            "train MSE 20:\t 0.0019360088044777513\n",
            "train MSE 40:\t 0.0019587569404393435\n",
            "test MSE 93:\t 0.0019491815473884344\n",
            "train MSE 0:\t 0.001956458203494549\n",
            "train MSE 20:\t 0.0019644100684672594\n",
            "train MSE 40:\t 0.0019379355944693089\n",
            "test MSE 94:\t 0.0019387565553188324\n",
            "train MSE 0:\t 0.0019283307483419776\n",
            "train MSE 20:\t 0.0019424454076215625\n",
            "train MSE 40:\t 0.0019423045450821519\n",
            "test MSE 95:\t 0.0019128434360027313\n",
            "train MSE 0:\t 0.0019901925697922707\n",
            "train MSE 20:\t 0.0019510971615090966\n",
            "train MSE 40:\t 0.0019376544514670968\n",
            "test MSE 96:\t 0.002048364607617259\n",
            "train MSE 0:\t 0.0019513261504471302\n",
            "train MSE 20:\t 0.001992876175791025\n",
            "train MSE 40:\t 0.001937410095706582\n",
            "test MSE 97:\t 0.0019857941661030054\n",
            "train MSE 0:\t 0.0019480825867503881\n",
            "train MSE 20:\t 0.0019178999355062842\n",
            "train MSE 40:\t 0.0019210384925827384\n",
            "test MSE 98:\t 0.0020006857812404633\n",
            "train MSE 0:\t 0.0020122278947383165\n",
            "train MSE 20:\t 0.001872476190328598\n",
            "train MSE 40:\t 0.001955965766683221\n",
            "test MSE 99:\t 0.0019304597517475486\n",
            "train MSE 0:\t 0.0019176495261490345\n",
            "train MSE 20:\t 0.0020096232183277607\n",
            "train MSE 40:\t 0.001999232918024063\n",
            "test MSE 100:\t 0.0019655167125165462\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2MWuF_kbl6jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_path = \"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/data/\"\n",
        "X = np.loadtxt(dic_path + 'datacsv1.csv', delimiter=';', dtype=np.float32)\n",
        "y = np.loadtxt(dic_path + 'datacsv.csv', delimiter=';', dtype=np.float32)\n",
        "X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X_train = np.zeros([X_train1.shape[0], 1, 16, 12]) # shape: count * 1 * 16(angle) * 12(voltage)\n",
        "X_test = np.zeros([X_test1.shape[0], 1, 16, 12])\n"
      ],
      "metadata": {
        "id": "6VSC259sg5So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(X_train1.shape[0]):\n",
        "    X_train[i, 0, :, :] = X_train1[i].reshape(16, 12)\n",
        "for i in range(X_test1.shape[0]):\n",
        "    X_test[i, 0, :, :] = X_test1[i].reshape(16, 12)"
      ],
      "metadata": {
        "id": "CNDGwOAthzeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0][0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Bn4G_ChlgT",
        "outputId": "8b6fcd95-2ba4-4646-b32b-69f74b4cb4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DealDataset(Dataset):\n",
        "    \"\"\"\n",
        "        下载数据、初始化数据，都可以在这里完成\n",
        "        当我们集成了一个 Dataset类之后，我们需要写 len 方法，该方法提供了dataset的大小； getitem 方法， 该方法支持从 0 到 len(self)的索引\n",
        "    \"\"\"\n",
        "    def __init__(self,a):\n",
        "        dic_path = \"/content/drive/MyDrive/Colab Notebooks/EIT/EITDeepLearning/data\"\n",
        "        X = np.loadtxt(dic_path + 'datacsv1.csv', delimiter=',', dtype=np.float32)\n",
        "        y = np.loadtxt('G:\\\\r=0.15\\\\junyun\\\\y.csv', delimiter=',', dtype=np.float32)\n",
        "        X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "        X_train = np.zeros([X_train1.shape[0], 1, 16, 12])\n",
        "        X_test = np.zeros([X_test1.shape[0], 1, 16, 12])\n",
        "        for i in range(X_train1.shape[0]):\n",
        "            X_train[i, 0, :, :] = X_train1[i].reshape(16, 12)\n",
        "        for i in range(X_test1.shape[0]):\n",
        "            X_test[i, 0, :, :] = X_test1[i].reshape(16, 12)\n",
        "        if a=='train':\n",
        "            self.x = X_train\n",
        "            self.y = y_train\n",
        "            self.len = X_train.shape[0]\n",
        "        elif a=='test':\n",
        "            self.x = X_test\n",
        "            self.y = y_test\n",
        "            self.len = X_test.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# 实例化这个类，然后我们就得到了Dataset类型的数据.\n",
        "dealDataset1 = DealDataset(a='train')\n",
        "\n",
        "#将这个类传给DataLoader\n",
        "train_loader = DataLoader(dataset=dealDataset1,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True)\n",
        "\n",
        "# 定义网络结构\n",
        "class CNNnet(torch.nn.Module):\n",
        "    def __init__(self, layer_widths, layer_centres, basis_func):\n",
        "        super(CNNnet,self).__init__()\n",
        "        self.rbf_layers = nn.ModuleList()\n",
        "        self.linear_layers = nn.ModuleList()\n",
        "        self.conv1_1 = nn.Sequential(\n",
        "            # (1, 16, 12)pytorch输入不用定义大小，因为参数过多写成nn.Conv2d(1,64,3,1，1)形式容易出错，有的参数默认了\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,#单通道\n",
        "                out_channels=64,#64通道\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1#零填充\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64),#批量归一化\n",
        "            nn.ELU(),#ELU激活函数\n",
        "        )\n",
        "        self.conv1_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=64,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)#最大池化层，核大小为2\n",
        "        )\n",
        "        self.conv2_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv2_2 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=128,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv3_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=256,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4_1 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=256,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_2 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_3 = nn.Sequential(\n",
        "            # (1, 28, 28)\n",
        "            nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "        )\n",
        "        self.conv4_4 = nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=512,\n",
        "                out_channels=512,\n",
        "                kernel_size=3,  # 卷积filter, 移动块长\n",
        "                stride=1,  # filter的每次移动步长\n",
        "                padding=1\n",
        "            ),\n",
        "            torch.nn.BatchNorm2d(512),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2,ceil_mode=True)#平均池化层，核大小为2，2×1经过这层变成1×0，报错，但有ceil_mode=True为向上取整，变成1×1\n",
        "        )\n",
        "        for i in range(len(layer_widths) - 1):\n",
        "            self.rbf_layers.append(rbf.RBF(layer_widths[i], layer_centres[i], basis_func))\n",
        "            self.linear_layers.append(nn.Linear(layer_centres[i], layer_widths[i + 1]))\n",
        "        self.mlp2 = torch.nn.Linear(512,576) #输出层，512是输入这层的大小，576是输出的大小\n",
        "    '''\n",
        "    前向传播\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.conv3_4(x)\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.conv4_4(x)\n",
        "        x = x.view(x.size(0),-1)#四维数据（数据量，通道，纵向，横向），展开为二维（数据量，只有横向）\n",
        "        for i in range(len(self.rbf_layers)):\n",
        "            x = self.rbf_layers[i](x)\n",
        "            x = self.linear_layers[i](x)\n",
        "        x = self.mlp2(x)\n",
        "        return x\n",
        "layer_widths = [512] #神经元数量\n",
        "layer_centres = [40]\n",
        "basis_func = rbf.gaussian #初始偏置\n",
        "\n",
        "model = CNNnet(layer_widths, layer_centres, basis_func) #初始化模型\n",
        "print(model)  #显示模型参数\n",
        "model = model.float() #模型参数转为float型\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device) #训练数据和模型数据类型要统一，并且pytorch-gpu数据类型要变成指定类型\n",
        "\n",
        "loss_func = torch.nn.MSELoss() #定义损失函数\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.3, momentum=0.9) #动量梯度下降法\n",
        "\n",
        "dealDataset2 = DealDataset(a='test')  #测试集数据\n",
        "\n",
        "test_loader = DataLoader(dataset=dealDataset2,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True)\n",
        "\n",
        "'''\n",
        "下面矩阵存放训练过程中损失函数等数据\n",
        "'''\n",
        "loss_count = []\n",
        "iter_loss = []\n",
        "batch_loss = []\n",
        "test_loss = []\n",
        "epochs=100 #轮数\n",
        "for epoch in range(epochs):\n",
        "    for i, (x, y)in enumerate(train_loader):\n",
        "        batch_x = Variable(x).to(torch.float32) # torch.Size([, 1, 16, 12])\n",
        "        batch_x = batch_x.cuda()\n",
        "        batch_y = Variable(y).to(torch.float32) # torch.Size([576])\n",
        "        batch_y = batch_y.cuda()\n",
        "        out = model(batch_x)        # 获取最后输出\n",
        "        loss = loss_func(out, batch_y)        # 获取损失\n",
        "        batch_loss.append(loss.cuda().data.cpu().numpy())    # 使用优化器优化损失\n",
        "        opt.zero_grad()  # 清空上一步残余更新参数值\n",
        "        loss.backward() # 误差反向传播，计算参数更新值\n",
        "        opt.step() # 将参数更新值施加到net的parmeters上\n",
        "        '''\n",
        "        每20个数据显示一次训练集均方误差\n",
        "        '''\n",
        "        if i%20 == 0:\n",
        "            loss_count.append(loss)\n",
        "            print('train MSE {}:\\t'.format(i), loss.item())\n",
        "            torch.save(model,r'C:\\Users\\luoxinyu\\Desktop\\log_CNN')\n",
        "\n",
        "    for a,b in test_loader:\n",
        "        test_x = Variable(a).to(torch.float32)\n",
        "        test_x = test_x.cuda()\n",
        "        test_y = Variable(b).to(torch.float32)\n",
        "        test_y = test_y.cuda()\n",
        "        out = model(test_x)\n",
        "        loss = loss_func(out, test_y)\n",
        "        test_loss.append(loss.cuda().data.cpu().numpy())\n",
        "        '''\n",
        "        每轮示一次训练集均方误差\n",
        "        '''\n",
        "        print('test MSE {}:\\t'.format(epoch+1), loss.item())\n",
        "        break\n",
        "    iter_loss.append(np.average(np.array(batch_loss)))\n",
        "\n",
        "'''\n",
        "绘制测试集 轮数与均方误差图像\n",
        "'''\n",
        "x = np.arange(epochs)\n",
        "y = np.array(iter_loss)\n",
        "plt.plot(x, y)\n",
        "plt.title('pic')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iwatjgIfULA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}